
- Pods are the fundamental units of deployment
- Each pod has one or more containers that may expose ports
- Each pod has a routable IP address assigned to it
- Pod Ip address may change during its life time
- Labels are used to logically identify pods that match specific criteria
- Replication Controller's selectors matches the pods based on the labels
- Replication Controllers maintain the desired count all the time
- Replica sets are the next level to Relication Controllers which uses Annotations instead of Labels/Selectors
- Replica sets matches pods using the complex expressions using Annotations

- Daemon Set creates one pod per node ( including master ).
  usecases: logging, Monitoring..etc
  


- A service is an abstraction of logical set of pods defined by a policy
- It acts a intermeidary for the pods to talk each other
- 

- The DNS server watches the kubernetes API ( Kube-Master ) for new services that are created.
- The DNS server creates a set of DNS records for each service
- Services can be resolved by the name with in the same namespace
- Pods in other namespace can access the service by adding the namespace to the DNS path
  e.g: myService.myNamespace
  
  
Best Practise
 - Deployments provides declarative update for pods & replica sets
 - Deployment object is flexible for managing and scaling applications is kubernetes
 - Deployment enables to perform rolling updates with zero downtime.
 - Deployment enables to rollback to previous/last deployment.
 
 

Kube-Master

It consists of 3 main components
- API : Exposes REST API's to the consumers to talk to kubernetes cluster
- Controller : its job is to controll the cluster & always maintain its desired state.
- Scheduler : Its job is to pickup the right node and run the pod

Kube-Worker

- Kubelet : It acts like an agent, communicates with kube-master all the time.
kubectl explain ## gives all alias names
kubectl config view
kubectl config use-context <<ContextName>>
kubectl describe pod <<podname>>
kubectl describe node <<nodename>>
kubectl describe svc <<servicename>>
kubectl get nodes
kubectl get svc
kubectl get pods
kubectl get deployments
kubectl create -f web-pod.yml -f web-rc.yml -f web-svc.yml ## to create pod,replication controller & services
kubectl apply -f web-svc.yml  ## to apply modified changes

kubectl cordon <<NODE IP>> ## Disables scheduling new pods to this node. Useful if we want to perform any maintainence
to it like patch update. and to bring it back to scheduling run the below one

kubectl uncordon <<NODE IP>>
kubectl drain <<Node>> --force . ## more powerful than cordon, it will gracefully moves the pods to another node, if pods are
part of replicaset/relicationController. Behind the scenes it will cordon & deletes the running pod by respecting ReplicaSet 
behavior

kubectl port-forward <<podname>> port:port ## it bypasses exposing ports using service & exposes port only to localhost,
which helps us to debug the webapplication

kubectl cp ./test.html podname:/usr/src/test.html  ## copies file from host machine to pod directly & vice-versa
KUBE_EDITOR="vim" kubectl edit pod/web

kubectl create secret generic dbsecret --from-file=./username.txt --from-file=./password.txt
kubectl get secret -o yaml
kubectl get nodes -o json | 
        jq ".items[] | {name:.metadata.name} + .status.capacity"
        
Kube-DashBoard

- To create a Dashboard
  kubectl apply -f https://goo.gl/Qamqab
  
  Edit service file and change the type to NodePort from ClusterIP
  kubectl -n kube-system edit svc kubernetes-dashboard

- To grant access run the below
  kubectl apply -f https://goo.gl/CHsLTA 
  
Helm Installation

curl -O https://storage.googleapis.com/kubernetes-helm/helm-v2.11.0-linux-amd64.tar.gz
chmod 777 helm-v2.11.0-linux-amd64.tar.gz
tar -zxvf helm-v2.11.0-linux-amd64.tar.gz
mv linux-amd64/helm /usr/local/bin/helm
vim ~/.bash_profile
export PATH = $PATH:usr/local/bin 
helm init
helm version

For mac -> brew install kubernetes-helm

Install Spinnaker

kubectl create serviceaccount --namespace kube-system tiller 
kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller
kubectl patch deploy --namespace kube-system tiller-deploy -p '{"spec":{"template":{"spec":{"serviceAccount":"tiller"}}}}'

curl -Lo values.yaml https://raw.githubusercontent.com/kubernetes/charts/master/stable/spinnaker/values.yaml
helm install -n kubelive stable/spinnaker -f values.yaml --timeout 300  --version 0.3.5 --namespace spinnaker

install istio
https://thenewstack.io/tutorial-blue-green-deployments-with-kubernetes-and-istio/

curl -L https://git.io/getLatestIstio | sh -
kubectl apply -f install/kubernetes/helm/istio/templates/crds.yaml
## First change LoadBalance to NodePort & then run this file
kubectl apply -f install/kubernetes/istio-demo.yaml 




